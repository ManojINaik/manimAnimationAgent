#!/usr/bin/env python3
"""
Test: Verify TOP 3 URL Content Extraction

This script tests that the Tavily integration extracts content
from exactly the top 3 URLs, prioritized by source type and relevance.
"""

import os
import sys
from src.utils.tavily_search import TavilyErrorSearchEngine, search_error_solution

def test_top_3_extraction():
    """Test that only top 3 URLs get content extracted"""
    print("ğŸ¯ Testing TOP 3 URL Content Extraction")
    print("="*50)
    
    # Use a common Manim error
    test_error = """
ValueError: all the input arrays must have same number of dimensions, but the 
array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)
"""
    
    code_context = """
triangle = Polygon([(0, 0, 0), (2, 0, 0), (2, 1.5, 0)], stroke_width=2)
"""
    
    print("ğŸ“‹ **Test Configuration:**")
    print("   Error: Polygon ValueError - dimension mismatch")
    print("   Expected: Extract content from TOP 3 URLs only")
    print("   Priority: docs.manim.community > GitHub > Stack Overflow")
    print()
    
    try:
        # Run error resolution with content extraction
        result = search_error_solution(
            test_error, 
            code_context, 
            extract_content=True  # Enable content extraction
        )
        
        # Analyze extraction results
        solutions = result['search_results'].get('solutions', [])
        extracted_count = 0
        
        print("ğŸ” **Extraction Results:**")
        print(f"   Total Solutions Found: {len(solutions)}")
        
        for i, solution in enumerate(solutions, 1):
            has_extracted = bool(solution.get('extracted_content'))
            content_length = len(solution.get('extracted_content', '')) if has_extracted else 0
            
            status = "âœ… EXTRACTED" if has_extracted else "âŒ Not extracted"
            
            print(f"   {i}. {solution['source_type']}: {status}")
            print(f"      Title: {solution['title'][:60]}...")
            print(f"      URL: {solution['url'][:70]}...")
            if has_extracted:
                print(f"      Content Length: {content_length:,} characters")
                extracted_count += 1
            print()
        
        print("ğŸ“Š **Summary:**")
        print(f"   âœ… URLs with extracted content: {extracted_count}")
        print(f"   ğŸ¯ Target (max 3): 3")
        print(f"   âœ“ Extraction limited correctly: {extracted_count <= 3}")
        
        if extracted_count <= 3:
            print("   ğŸ‰ SUCCESS: Extracting from TOP 3 URLs only!")
        else:
            print("   âš ï¸ WARNING: Extracting from more than 3 URLs")
        
        # Show priority order
        extracted_solutions = [sol for sol in solutions if sol.get('extracted_content')]
        if extracted_solutions:
            print("\nğŸ† **Priority Order (Extracted URLs):**")
            for i, sol in enumerate(extracted_solutions, 1):
                priority = {
                    "official_docs": "ğŸ¥‡ HIGHEST",
                    "github": "ğŸ¥ˆ MEDIUM", 
                    "stackoverflow": "ğŸ¥‰ LOWER",
                    "reddit": "4ï¸âƒ£ LOW",
                    "other": "5ï¸âƒ£ LOWEST"
                }.get(sol['source_type'], "â“ UNKNOWN")
                
                print(f"   {i}. {sol['source_type']}: {priority}")
                print(f"      Relevance Score: {sol.get('relevance_score', 0):.2f}")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")

def demo_extraction_limits():
    """Demonstrate the extraction limits and configuration"""
    print("\nâš™ï¸ **Extraction Configuration Demo**")
    print("="*50)
    
    print("ğŸ“‹ **Current Settings:**")
    print("   â€¢ Max extractions: 3 URLs")
    print("   â€¢ Content per URL: Up to 8,000 characters")
    print("   â€¢ Total content: Up to 24,000 characters")
    print("   â€¢ Format: Markdown (cleaned)")
    print()
    
    print("ğŸ† **Priority Order:**")
    print("   1. ğŸ¥‡ docs.manim.community (Official documentation)")
    print("   2. ğŸ¥ˆ github.com (Community repos and issues)")
    print("   3. ğŸ¥‰ stackoverflow.com (Community Q&A)")
    print("   4. 4ï¸âƒ£ reddit.com (Forums - if found)")
    print("   5. 5ï¸âƒ£ other (Other sources)")
    print()
    
    print("âš¡ **Performance Impact:**")
    print("   â€¢ 3 URLs Ã— ~1-2 seconds each = ~3-6 seconds total")
    print("   â€¢ Balanced between context richness and speed")
    print("   â€¢ Optimal for LLM token limits")
    print()
    
    print("ğŸ¯ **Why TOP 3?**")
    print("   âœ… Sufficient context for most errors")
    print("   âœ… Respects API rate limits")
    print("   âœ… Fits within LLM context windows")
    print("   âœ… Prioritizes most authoritative sources")
    print("   âœ… Reasonable response time")

def main():
    """Run the TOP 3 URL extraction test"""
    print("ğŸ¬ TOP 3 URL Content Extraction Test")
    print("="*45)
    
    test_top_3_extraction()
    demo_extraction_limits()
    
    print("\nğŸ‰ **Test Complete!**")
    print("The system now extracts content from exactly the TOP 3 URLs,")
    print("prioritized by source authority and relevance score!")

if __name__ == "__main__":
    main() 